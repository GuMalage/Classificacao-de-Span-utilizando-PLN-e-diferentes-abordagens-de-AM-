##  Classifica√ß√£o de Texto com BERT para a gera√ß√£o de embeddings + Machine Learning

O reposit√≥rio inclui um experimento completo de classifica√ß√£o de mensagens de texto (spam vs. n√£o spam) utilizando uma abordagem h√≠brida que combina **Modelos de Linguagem Pr√©-Treinados (BERT)** com algoritmos cl√°ssicos de Machine Learning.

### üîç Pipeline Utilizado

O fluxo experimental segue as seguintes etapas:

1. **Carregamento do Dataset**
   - Base de dados de classifica√ß√£o de mensagens (spam/ham).
   - Leitura e organiza√ß√£o utilizando Pandas.

2. **Pr√©-processamento Textual**
   - Limpeza de caracteres especiais
   - Normaliza√ß√£o (lowercase)
   - Tokeniza√ß√£o com NLTK
   - Remo√ß√£o de stopwords

3. **Extra√ß√£o de Representa√ß√µes com BERT**
   - Utiliza√ß√£o do modelo `bert-base-uncased`
   - Tokeniza√ß√£o via `BertTokenizer`
   - Extra√ß√£o do embedding do token `[CLS]`
   - Convers√£o para vetores num√©ricos

4. **Normaliza√ß√£o dos Vetores**
   - Padroniza√ß√£o com `StandardScaler`

5. **Treinamento de Modelos Supervisionados**
   Os embeddings extra√≠dos pelo BERT s√£o utilizados como entrada para diferentes classificadores:

   - Support Vector Machine (SVM)
   - K-Nearest Neighbors (KNN)
   - Decision Tree
   - Random Forest

6. **Avalia√ß√£o**
   - Divis√£o treino/teste com estratifica√ß√£o
   - C√°lculo de acur√°cia

---

## ü§ñ Abordagem Metodol√≥gica

A estrat√©gia adotada separa o problema em duas camadas:

- **Camada 1 ‚Äì Representa√ß√£o Sem√¢ntica:**  
  O modelo BERT √© utilizado como extrator de caracter√≠sticas, capturando informa√ß√µes contextuais profundas do texto.

- **Camada 2 ‚Äì Classifica√ß√£o:**  
  Algoritmos cl√°ssicos de Machine Learning s√£o aplicados sobre os embeddings gerados, permitindo comparar diferentes estrat√©gias de decis√£o.

Essa abordagem combina o poder sem√¢ntico dos Transformers com a interpretabilidade e efici√™ncia computacional de modelos tradicionais.

---

## üìä Modelos Implementados

O reposit√≥rio cont√©m implementa√ß√µes completas utilizando:

- SVM (Support Vector Machine)
- KNN (K-Nearest Neighbors)
- Decision Tree
- Random Forest

## üéØ Objetivo do Experimento

Demonstrar como modelos pr√©-treinados podem ser integrados a algoritmos cl√°ssicos de Machine Learning para tarefas de classifica√ß√£o de texto, evidenciando diferen√ßas de desempenho entre abordagens baseadas em dist√¢ncia, margem e √°rvores de decis√£o.
